{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport re\nimport torch.nn as nn\nimport time\n\nfrom sklearn.model_selection import GroupKFold\n\nimport albumentations \nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torchvision\nfrom albumentations import transforms\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\n\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/vinbigdata-256-image-dataset/vinbigdata/train.csv\")\nsample = pd.read_csv(\"../input/vinbigdata-chest-xray-abnormalities-detection/sample_submission.csv\")\n\nIMG_SIZE = 256\ntrain_df['xmin'] = (train_df['x_min']/train_df['width'])*IMG_SIZE\ntrain_df['ymin'] = (train_df['y_min']/train_df['height'])*IMG_SIZE\ntrain_df['xmax'] = (train_df['x_max']/train_df['width'])*IMG_SIZE\ntrain_df['ymax'] = (train_df['y_max']/train_df['height'])*IMG_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_folds(df):\n    \n    df[\"kfold\"] = -1\n    df = df.sample(frac=1).reset_index(drop=True)\n    y = df.class_id.values\n    \n    #Group K Fold\n    gf = GroupKFold(n_splits=5)\n    \n    #We group by image_id because the same group should not appear in two different folds\n    for idx, (train_idx, valid_idx) in enumerate(gf.split(X=df, y=y, groups=df.image_id.values)):\n        df.loc[valid_idx, \"kfold\"] = idx\n\n    return df\n\ndf = make_folds(df)\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['class_id'] != 14].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.fillna(0, inplace=True)\n#df.loc[df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n\n\n# FasterRCNN handles class_id==0 as the background.\n# df[\"class_id\"] = df[\"class_id\"] + 1\n# df.loc[df[\"class_id\"] == 15, [\"class_id\"]] = 0\n\n# df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"class_name\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values(by=\"class_id\").head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = df[\"class_name\"].unique().tolist()\ntotal_classes = [\"Unknown\"] + classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"image_id\"].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = {\n    \"image_dir\":\"../input/vinbigdata-256-image-dataset/vinbigdata/train\",\n    \"num_epochs\": 10,\n    \"lr_rate\": 1e-6,\n    \"num_classes\":15,\n    \"batch_size\":8,\n    \"test_dir\": \"../input/vinbigdata-256-image-dataset/vinbigdata/test\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VinBigData(Dataset):\n    def __init__(self, df, img_dir, istransforms=None, transforms=None, isTest=False):\n        super(VinBigData, self).__init__()\n        self.df = df\n        self.image_ids = self.df[\"image_id\"].unique()\n        self.img_dir = img_dir\n        self.istransforms = istransforms\n        self.transforms = transforms\n        self.isTest = isTest\n    \n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self, idx):\n        image_id = self.image_ids[idx]\n        \n        record = self.df[self.df[\"image_id\"] == image_id]\n        image = cv2.imread(f'{self.img_dir}/{image_id}.png', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        \n        if self.isTest == True:\n            image = np.transpose(image, (2, 1, 0))\n            return torch.tensor(image, dtype=torch.float32), image_id\n\n        bb_box = record[[\"xmin\",\"ymin\",\"xmax\",\"ymax\"]].values\n        area = (bb_box[:, 3] - bb_box[:,1]) * (bb_box[:,2] - bb_box[:, 0])\n        \n        iscrowd = torch.ones((record.shape[0],), dtype=torch.float32)\n        \n        area = torch.tensor(area, dtype=torch.float32)\n        \n        labels = torch.as_tensor((record.class_id.values + 1), dtype=torch.int64)\n        \n        targets = {}\n        targets[\"labels\"] = labels\n        targets[\"area\"] = area\n        targets[\"iscrowd\"] = iscrowd\n        targets[\"image_id\"] = torch.tensor([idx])\n        targets[\"boxes\"] = torch.tensor(bb_box, dtype=torch.float32)\n        \n        if self.istransforms is not None:\n            image = self.transforms(image)\n        \n\n        return image, targets\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = VinBigData(df, img_dir=config[\"image_dir\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[0][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\nnum_classes = 15\n\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms as T\n\ndef get_transform(train):\n    transforms = []\n    transforms.append(T.ToTensor())\n    if train:\n        transforms.append(T.RandomHorizontalFlip(0.5))\n        transforms.append(T.Normalize(mean=(0,0,0), std=(1,1,1)))\n    else:\n        transforms.append(T.Normalize(mean=(0,0,0), std=(1,1,1)))\n    return T.Compose(transforms)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ndataset = VinBigData(df, config[\"image_dir\"], istransforms=True, transforms=get_transform(train=True))\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=collate_fn)\n\nimages, targets = next(iter(data_loader))\nimages = list(image  for image in images)\ntargets = [{k: v for k, v in t.items()} for t in targets]\noutput = model(images, targets)\n\nmodel.eval()\nx = [torch.randn(3, 256,256), torch.randn(3, 500, 400)]\npredictions= model(x)\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Device: {device}\")\n    \nmodel.to(device)\n\nlr_rate = 1e-6\n\nepochs = 20\n\nlr_scheduler = None\n\nparams = [p for p in model.parameters() if p.requires_grad]\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n\nnum_folds = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\nnum_epochs = config[\"num_epochs\"]\n\ndataset = VinBigData(df, config[\"image_dir\"], istransforms=True, transforms=get_transform(train=True))\ntrain_data_loader = torch.utils.data.DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4, collate_fn=collate_fn)\nitr = 1\nnum_imgs = 0\n\nfor epoch in range(num_epochs):\n    \n    loss_value = 0.0\n    num_images= 0\n    loop = tqdm(enumerate(train_data_loader), total = len(train_data_loader))\n    \n    for batch (images, targets) in tqdm(loop):\n        \n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n        \n        print(type(loss_dict))\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value += losses.item() \n        num_images += len(images)\n        \n        print(\"Loss:{} num_images {}\".format(loss_value, num_images))\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if itr % 20 == 0:\n            print(f\"Iteration #{itr} loss: {loss_value/itr}\")\n\n        itr += 1\n        \n\n    \n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n\n    print(f\"Epoch #{epoch} loss: {loss_value/len(train_data_loader)}\")   \n    # print(\"Saving epoch's state...\")\n    # torch.save(model.state_dict(), f\"model_state_epoch_{epoch}.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\ndef run(validation_index):\n\n    train_data = df\n    #train_data = df[df[\"kfold\"] != validation_index]\n    test_data = df[df[\"kfold\"] == validation_index]\n    \n    dataset = VinBigData(train_data, config[\"image_dir\"], istransforms=True, transforms=get_transform(train=True))\n    train_data_loader = torch.utils.data.DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4, collate_fn=collate_fn)\n    \n    dataset = VinBigData(test_data, config[\"image_dir\"], istransforms=True, transforms=get_transform(train=False))\n    valid_data_loader = torch.utils.data.DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4, collate_fn=collate_fn) \n    \n    \n    training_dict = {\"train\":train_data_loader, \"valid\":valid_data_loader}\n    \n    for epoch in range(config[\"num_epochs\"]):\n        \n        \n        \n        num_correct = 0\n        current_loss = 0.0\n\n        best_loss = float(\"inf\")\n        \n        for phase in [\"train\"]:\n            \n            if phase == \"train\":\n                scheduler.step()\n                model.train()\n\n                \n            num_samples = 0\n            loss_value = 0.0\n            \n            loop = tqdm(enumerate(training_dict[phase]), total = len(training_dict[phase]))\n            \n            for batch, (train_images, targets) in loop:\n                \n                \n                train_images = list(image.to(device) for image in train_images)\n                \n                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n                \n                loss_dict = model(train_images, targets)\n                \n                losses = sum(loss for loss in loss_dict.values())\n                \n                loss_value += losses.item()\n                \n                optimizer.zero_grad()\n                num_samples += 1\n                \n                with torch.set_grad_enabled(phase == \"train\"):\n                    \n                    losses.backward()\n                    optimizer.step()\n            \n            loss_value = loss_value / len(training_dict[phase])\n            print('{}/{} {} Loss: {:.4f}'.format(epoch, config[\"num_epochs\"], phase, loss_value))\n            \n            avg_loss = loss_value\n            if avg_loss < best_loss:\n                best_loss = avg_loss\n                print('Best loss found at Epoch:{}, loss:{}'.format(epoch, best_loss))\n                output = f'./fasterrcnn_model_{validation_index}.pt'\n                torch.save(model.state_dict(), f'./fasterrcnn_model_{validation_index}.pt')\n        \n        \n        print(\"Fold is {}, avg loss:{} best loss{} \".format(validation_index, avg_loss,best_loss))\n                    \n#for fold in range(num_folds):\nrun(0)   \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load(\"./fasterrcnn_model_0.pt\"))\nmodel.to(device)\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/vinbigdata-256-image-dataset/vinbigdata/test.csv\")\ntrain = pd.read_csv(\"../input/vinbigdata-256-image-dataset/vinbigdata/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ntest_dataset = VinBigData(df, config[\"image_dir\"],istransforms=True ,transforms=get_transform(train=True))\n\ntest_data_loader = DataLoader(\n    test_dataset,\n    batch_size=8,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n    collate_fn=collate_fn\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ntest_dataset = VinBigData(test, config[\"test_dir\"], istransforms=True, transforms=get_transform(train=False), isTest=True)\n\ntest_data_loader = DataLoader(\n    test_dataset,\n    batch_size=8,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n    collate_fn=collate_fn\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_prediction_string(labels, boxes, scores):\n    pred_strings = []\n    for j in zip(labels, scores, boxes):\n        pred_strings.append(\"{0} {1:.4f} {2} {3} {4} {5}\".format(\n            j[0], j[1], j[2][0], j[2][1], j[2][2], j[2][3]))\n\n    return \" \".join(pred_strings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.5\nresults = []\n\nwith torch.no_grad():\n    \n    for images, image_ids in test_data_loader:\n        \n        #print(images[0].shape)\n        images = list(image.to(device) for image in images)\n        outputs = model(images)\n        \n        for i, image in enumerate(images):\n            \n            image_id = image_ids[i]\n            \n            result = {\n                'image_id': image_id,\n                'PredictionString': '14 1.0 0 0 1 1'\n            }\n        \n            print(outputs[i]['scores'])\n            boxes = outputs[i]['boxes'].data.cpu().numpy()\n            labels = outputs[i]['labels'].data.cpu().numpy()\n            scores = outputs[i]['scores'].data.cpu().numpy()\n            \n            if len(boxes) > 0:\n                \n\n                labels = labels - 1\n                labels[labels == -1] = 14\n                \n                selected = scores >= threshold\n\n                boxes = boxes[selected].astype(np.float32)\n                scores = scores[selected]\n                labels = labels[selected]\n                \n                print(labels)\n                \n                if len(boxes) > 0:\n                    result = {\n                        'image_id':image_id,\n                        'PredictionString': format_prediction_string(labels, boxes, scores)\n                    }\n                    \n                    \n            results.append(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs[0]['boxes'].data.cpu().numpy().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs[0]['labels'].data.cpu().numpy().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numofRows = 3\ngrid = [\"aabba\",\"aabbba\",\"aaacb\"]\n\nvisited = [len(grid[0]) * [0]] * len(grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visited","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"queue = [grid[0][0]]\n\nmoves = [[1,0],[-1,0],[0,1],[0,-1]]\nrow_max = numofRows\ncol_max = len(grid[0])\n\nstart_row = start_col = 0\n\nwhile len(queue):\n    \n    \n    prev = grid[start_row][start_col]\n    for i in range(len(moves)):\n    \n        if (start_row >= row_max or start_col >= col_max or grid[start_row][start_col] != prev):\n        \n        \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis = [[\"item1\",10,15], [\"item2\",3,4], [\"item3\",17,8],[\"item4\",27,3]]\n\nsortParamter= 2\nsortOrder = 0\nitemsPerPage = 2\npageNumber = 1\n\n\nlis.sort(reverse = sortOrder, key = lambda x:x[sortParamter])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis[pageNumber*itemsPerPage : pageNumber*itemsPerPage+1+itemsPerPage]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}